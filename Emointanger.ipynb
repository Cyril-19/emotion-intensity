{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.read_csv(\"Desktop/emoint tweet/anger-ratings-0to1.train.txt\", delimiter='\\t', header=None)\n",
    "df1.columns = ['Id', 'tweet', 'emotion', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id                                              tweet emotion  score\n",
      "0    10000  How the fu*k! Who the heck! moved my fridge!.....   anger  0.938\n",
      "1    10001  So my Indian Uber driver just called someone t...   anger  0.896\n",
      "2    10002  @DPD_UK I asked for my parcel to be delivered ...   anger  0.896\n",
      "3    10003  so ef whichever butt wipe pulled the fire alar...   anger  0.896\n",
      "4    10004  Don't join @BTCare they put the phone down on ...   anger  0.896\n",
      "..     ...                                                ...     ...    ...\n",
      "852  10852   rose incense are the best thing I've ever bought   anger  0.125\n",
      "853  10853         @jaaames1993 Literally burst out laughing.   anger  0.067\n",
      "854  10854           Follow up. Follow through. Be . #success   anger  0.125\n",
      "855  10855  Wrinkles should merely hide where frown have b...   anger  0.125\n",
      "856  10856  Love the new song I can't stop thinking about ...   anger  0.083\n",
      "\n",
      "[857 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import emoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", tweet)\n",
    "    \n",
    "    return tweet\n",
    "df1['tweet'] = df1['tweet'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mentions(tweet):\n",
    "    return re.sub(r'@\\w+', '', tweet)\n",
    "\n",
    "df1['tweet'] = df1['tweet'].apply(remove_mentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s#@]', '', text) \n",
    "    text = re.sub(r'\\d+', '', text) \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df1['tweet'] = df1['tweet'].apply(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>how the fuk who the heck moved my fridge shoul...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>so my indian uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>i asked for my parcel to be delivered to a pic...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>dont join they put the phone down on you talk ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>10852</td>\n",
       "      <td>rose incense are the best thing ive ever bought</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>10853</td>\n",
       "      <td>literally burst out laughing</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>10854</td>\n",
       "      <td>follow up follow through be #success</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>10855</td>\n",
       "      <td>wrinkles should merely hide where frown have b...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>10856</td>\n",
       "      <td>love the new song i cant stop thinking about y...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>857 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score\n",
       "0    10000  how the fuk who the heck moved my fridge shoul...   anger  0.938\n",
       "1    10001  so my indian uber driver just called someone t...   anger  0.896\n",
       "2    10002  i asked for my parcel to be delivered to a pic...   anger  0.896\n",
       "3    10003  so ef whichever butt wipe pulled the fire alar...   anger  0.896\n",
       "4    10004  dont join they put the phone down on you talk ...   anger  0.896\n",
       "..     ...                                                ...     ...    ...\n",
       "852  10852    rose incense are the best thing ive ever bought   anger  0.125\n",
       "853  10853                       literally burst out laughing   anger  0.067\n",
       "854  10854               follow up follow through be #success   anger  0.125\n",
       "855  10855  wrinkles should merely hide where frown have b...   anger  0.125\n",
       "856  10856  love the new song i cant stop thinking about y...   anger  0.083\n",
       "\n",
       "[857 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emoji(tweet):\n",
    "    text = emoji.demojize(tweet)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['tweet'] = df1['tweet'].apply(convert_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweets(tweet):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    return tokenizer.tokenize(tweet)\n",
    "\n",
    "df1['tweet'] = df1['tweet'].apply(tokenize_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>[how, the, fuk, who, the, heck, moved, my, fri...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>[so, my, indian, uber, driver, just, called, s...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>[i, asked, for, my, parcel, to, be, delivered,...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>[so, ef, whichever, butt, wipe, pulled, the, f...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>[dont, join, they, put, the, phone, down, on, ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>10852</td>\n",
       "      <td>[rose, incense, are, the, best, thing, ive, ev...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>10853</td>\n",
       "      <td>[literally, burst, out, laughing]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>10854</td>\n",
       "      <td>[follow, up, follow, through, be, #success]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>10855</td>\n",
       "      <td>[wrinkles, should, merely, hide, where, frown,...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>10856</td>\n",
       "      <td>[love, the, new, song, i, cant, stop, thinking...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>857 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score\n",
       "0    10000  [how, the, fuk, who, the, heck, moved, my, fri...   anger  0.938\n",
       "1    10001  [so, my, indian, uber, driver, just, called, s...   anger  0.896\n",
       "2    10002  [i, asked, for, my, parcel, to, be, delivered,...   anger  0.896\n",
       "3    10003  [so, ef, whichever, butt, wipe, pulled, the, f...   anger  0.896\n",
       "4    10004  [dont, join, they, put, the, phone, down, on, ...   anger  0.896\n",
       "..     ...                                                ...     ...    ...\n",
       "852  10852  [rose, incense, are, the, best, thing, ive, ev...   anger  0.125\n",
       "853  10853                  [literally, burst, out, laughing]   anger  0.067\n",
       "854  10854        [follow, up, follow, through, be, #success]   anger  0.125\n",
       "855  10855  [wrinkles, should, merely, hide, where, frown,...   anger  0.125\n",
       "856  10856  [love, the, new, song, i, cant, stop, thinking...   anger  0.083\n",
       "\n",
       "[857 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'he', 'in', 'is', 'it', 'its',\n",
    "    'of', 'on', 'that', 'the', 'to', 'was', 'were', 'will', 'with', 'i', 'you', 'your', 'so', 'this', 'all',\n",
    "    'am', 'or', 'but', 'if', 'my', 'me', 'we', 'us', 'our', 'we', 'up', 'down', 'out', 'just', 'how', 'why',\n",
    "    'when', 'where', 'here', 'there', 'about', 'more', 'most', 'some', 'any', 'few', 'many', 'much', 'not',\n",
    "    'only', 'other', 'same', 'such', 'no', 'nor', 'too', 'very', 'can', 'cannot', 'could', 'should', 'would',\n",
    "    'might', 'must', 'shall', 'will', 'isn', 'hasn', 'doesn', 'haven', 'didn', 'hadn', 'wasn', 'weren',\n",
    "    'wouldn', 'shouldn', 'ain', 'aren', 'ma'\n",
    "]\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [token for token in tokens if len(token) > 1 and token.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "df1['tweet'] = df1['tweet'].apply(remove_stopwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>[fuk, who, heck, moved, fridge, knock, landlor...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>[indian, uber, driver, called, someone, word, ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>[asked, parcel, delivered, pick, store, addres...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>[ef, whichever, butt, wipe, pulled, fire, alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>[dont, join, they, put, phone, talk, over, rud...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>10852</td>\n",
       "      <td>[rose, incense, best, thing, ive, ever, bought]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>10853</td>\n",
       "      <td>[literally, burst, laughing]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>10854</td>\n",
       "      <td>[follow, follow, through, #success]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>10855</td>\n",
       "      <td>[wrinkles, merely, hide, frown, have, been, ma...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>10856</td>\n",
       "      <td>[love, new, song, cant, stop, thinking]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>857 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score\n",
       "0    10000  [fuk, who, heck, moved, fridge, knock, landlor...   anger  0.938\n",
       "1    10001  [indian, uber, driver, called, someone, word, ...   anger  0.896\n",
       "2    10002  [asked, parcel, delivered, pick, store, addres...   anger  0.896\n",
       "3    10003  [ef, whichever, butt, wipe, pulled, fire, alar...   anger  0.896\n",
       "4    10004  [dont, join, they, put, phone, talk, over, rud...   anger  0.896\n",
       "..     ...                                                ...     ...    ...\n",
       "852  10852    [rose, incense, best, thing, ive, ever, bought]   anger  0.125\n",
       "853  10853                       [literally, burst, laughing]   anger  0.067\n",
       "854  10854                [follow, follow, through, #success]   anger  0.125\n",
       "855  10855  [wrinkles, merely, hide, frown, have, been, ma...   anger  0.125\n",
       "856  10856            [love, new, song, cant, stop, thinking]   anger  0.083\n",
       "\n",
       "[857 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def extract_features(tweet):\n",
    "    \n",
    "    tokenized_text = ' '.join(tweet)\n",
    "\n",
    "    input_ids = torch.tensor(tokenizer.encode(tokenized_text, add_special_tokens=True)).unsqueeze(0)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    \n",
    "   \n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    \n",
    "    features = last_hidden_states.squeeze(0).numpy()\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "df1['features'] = df1['tweet'].apply(extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>[fuk, who, heck, moved, fridge, knock, landlor...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "      <td>[[-0.048211165, 0.55411077, 0.17288177, -0.387...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>[indian, uber, driver, called, someone, word, ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[[-0.114754006, 0.2242083, 0.09101931, -0.1088...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>[asked, parcel, delivered, pick, store, addres...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[[-0.3445066, -0.026175018, 0.0032749637, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>[ef, whichever, butt, wipe, pulled, fire, alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[[-0.08527253, 0.29024652, 0.19312719, -0.0649...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>[dont, join, they, put, phone, talk, over, rud...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[[-0.19458191, 0.13260978, 0.12249434, -0.2312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>10852</td>\n",
       "      <td>[rose, incense, best, thing, ive, ever, bought]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "      <td>[[-0.5573598, 0.37391967, -0.46787184, 0.10334...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>10853</td>\n",
       "      <td>[literally, burst, laughing]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.067</td>\n",
       "      <td>[[-0.14927039, 0.18389827, 0.047589768, -0.044...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>10854</td>\n",
       "      <td>[follow, follow, through, #success]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "      <td>[[-0.21155725, 0.059810657, 0.18363638, 0.0126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>10855</td>\n",
       "      <td>[wrinkles, merely, hide, frown, have, been, ma...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "      <td>[[0.040475816, 0.2076654, 0.0045883185, -0.075...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>10856</td>\n",
       "      <td>[love, new, song, cant, stop, thinking]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.083</td>\n",
       "      <td>[[-0.052609857, -0.124588385, -0.080250956, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>857 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score  \\\n",
       "0    10000  [fuk, who, heck, moved, fridge, knock, landlor...   anger  0.938   \n",
       "1    10001  [indian, uber, driver, called, someone, word, ...   anger  0.896   \n",
       "2    10002  [asked, parcel, delivered, pick, store, addres...   anger  0.896   \n",
       "3    10003  [ef, whichever, butt, wipe, pulled, fire, alar...   anger  0.896   \n",
       "4    10004  [dont, join, they, put, phone, talk, over, rud...   anger  0.896   \n",
       "..     ...                                                ...     ...    ...   \n",
       "852  10852    [rose, incense, best, thing, ive, ever, bought]   anger  0.125   \n",
       "853  10853                       [literally, burst, laughing]   anger  0.067   \n",
       "854  10854                [follow, follow, through, #success]   anger  0.125   \n",
       "855  10855  [wrinkles, merely, hide, frown, have, been, ma...   anger  0.125   \n",
       "856  10856            [love, new, song, cant, stop, thinking]   anger  0.083   \n",
       "\n",
       "                                              features  \n",
       "0    [[-0.048211165, 0.55411077, 0.17288177, -0.387...  \n",
       "1    [[-0.114754006, 0.2242083, 0.09101931, -0.1088...  \n",
       "2    [[-0.3445066, -0.026175018, 0.0032749637, -0.1...  \n",
       "3    [[-0.08527253, 0.29024652, 0.19312719, -0.0649...  \n",
       "4    [[-0.19458191, 0.13260978, 0.12249434, -0.2312...  \n",
       "..                                                 ...  \n",
       "852  [[-0.5573598, 0.37391967, -0.46787184, 0.10334...  \n",
       "853  [[-0.14927039, 0.18389827, 0.047589768, -0.044...  \n",
       "854  [[-0.21155725, 0.059810657, 0.18363638, 0.0126...  \n",
       "855  [[0.040475816, 0.2076654, 0.0045883185, -0.075...  \n",
       "856  [[-0.052609857, -0.124588385, -0.080250956, 0....  \n",
       "\n",
       "[857 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 768)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>[fuk, who, heck, moved, fridge, knock, landlor...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "      <td>[[-0.048211165, 0.55411077, 0.17288177, -0.387...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>[indian, uber, driver, called, someone, word, ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[[-0.114754006, 0.2242083, 0.09101931, -0.1088...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>[asked, parcel, delivered, pick, store, addres...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[[-0.3445066, -0.026175018, 0.0032749637, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>[ef, whichever, butt, wipe, pulled, fire, alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[[-0.08527253, 0.29024652, 0.19312719, -0.0649...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>[dont, join, they, put, phone, talk, over, rud...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[[-0.19458191, 0.13260978, 0.12249434, -0.2312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10005</td>\n",
       "      <td>[blood, boiling]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[[-0.33847663, 0.43582797, -0.3691528, -0.0296...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10006</td>\n",
       "      <td>[youve, still, got, whole, season, wentworth, ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[[-0.2145357, 0.041926354, 0.31682923, -0.3384...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10007</td>\n",
       "      <td>[does, tracking, show, equipment, delivered, w...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[[-0.17867346, 0.54314536, 0.12850264, -0.2737...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10008</td>\n",
       "      <td>[legit, furious, him, people, fucking, idiots]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[[0.12987164, 0.45778227, 0.020973768, -0.0331...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10009</td>\n",
       "      <td>[suppose, work, do, wtf, dude, thanks, pissing...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[[0.11742496, 0.36254063, 0.1227451, -0.129079...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id                                              tweet emotion  score  \\\n",
       "0  10000  [fuk, who, heck, moved, fridge, knock, landlor...   anger  0.938   \n",
       "1  10001  [indian, uber, driver, called, someone, word, ...   anger  0.896   \n",
       "2  10002  [asked, parcel, delivered, pick, store, addres...   anger  0.896   \n",
       "3  10003  [ef, whichever, butt, wipe, pulled, fire, alar...   anger  0.896   \n",
       "4  10004  [dont, join, they, put, phone, talk, over, rud...   anger  0.896   \n",
       "5  10005                                   [blood, boiling]   anger  0.875   \n",
       "6  10006  [youve, still, got, whole, season, wentworth, ...   anger  0.875   \n",
       "7  10007  [does, tracking, show, equipment, delivered, w...   anger  0.875   \n",
       "8  10008     [legit, furious, him, people, fucking, idiots]   anger  0.875   \n",
       "9  10009  [suppose, work, do, wtf, dude, thanks, pissing...   anger  0.875   \n",
       "\n",
       "                                            features  \n",
       "0  [[-0.048211165, 0.55411077, 0.17288177, -0.387...  \n",
       "1  [[-0.114754006, 0.2242083, 0.09101931, -0.1088...  \n",
       "2  [[-0.3445066, -0.026175018, 0.0032749637, -0.1...  \n",
       "3  [[-0.08527253, 0.29024652, 0.19312719, -0.0649...  \n",
       "4  [[-0.19458191, 0.13260978, 0.12249434, -0.2312...  \n",
       "5  [[-0.33847663, 0.43582797, -0.3691528, -0.0296...  \n",
       "6  [[-0.2145357, 0.041926354, 0.31682923, -0.3384...  \n",
       "7  [[-0.17867346, 0.54314536, 0.12850264, -0.2737...  \n",
       "8  [[0.12987164, 0.45778227, 0.020973768, -0.0331...  \n",
       "9  [[0.11742496, 0.36254063, 0.1227451, -0.129079...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "features = df1['features'].tolist()\n",
    "\n",
    "\n",
    "padded_features = pad_sequences(features, padding='post')\n",
    "\n",
    "\n",
    "padded_df = df1.copy()\n",
    "padded_df['features'] = padded_features.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input feature shape: (857, 40, 768)\n"
     ]
    }
   ],
   "source": [
    "X = np.stack(padded_df['features'])\n",
    "\n",
    "print('Input feature shape:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (857, 40, 768)\n",
      "Output shape: (857,)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(padded_df['score'])    \n",
    "print(\"Input shape:\", X.shape)\n",
    "print(\"Output shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(X, (857, 40 * 768))  \n",
    "y = np.reshape(y, (857,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(857, 30720)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df1['score'].copy()\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 512)               15729152  \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,903,745\n",
      "Trainable params: 15,903,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(30720,), activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='mean_squared_error', patience=1, mode='min')\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1['tweet'] = df1['tweet'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "array = df1['tweet'].values\n",
    "\n",
    "tensor = tf.convert_to_tensor(array)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "35/35 [==============================] - 8s 179ms/step - loss: 0.0835 - mean_squared_error: 0.0835\n",
      "Epoch 2/15\n",
      "35/35 [==============================] - 6s 180ms/step - loss: 0.0538 - mean_squared_error: 0.0538\n",
      "Epoch 3/15\n",
      "35/35 [==============================] - 6s 177ms/step - loss: 0.0367 - mean_squared_error: 0.0367\n",
      "Epoch 4/15\n",
      "35/35 [==============================] - 6s 177ms/step - loss: 0.0294 - mean_squared_error: 0.0294\n",
      "Epoch 5/15\n",
      "35/35 [==============================] - 7s 186ms/step - loss: 0.0291 - mean_squared_error: 0.0291\n",
      "Epoch 6/15\n",
      "35/35 [==============================] - 7s 186ms/step - loss: 0.0237 - mean_squared_error: 0.0237\n",
      "Epoch 7/15\n",
      "35/35 [==============================] - 6s 182ms/step - loss: 0.0228 - mean_squared_error: 0.0228\n",
      "Epoch 8/15\n",
      "35/35 [==============================] - 6s 173ms/step - loss: 0.0176 - mean_squared_error: 0.0176\n",
      "Epoch 9/15\n",
      "35/35 [==============================] - 6s 174ms/step - loss: 0.0140 - mean_squared_error: 0.0140\n",
      "Epoch 10/15\n",
      "35/35 [==============================] - 6s 172ms/step - loss: 0.0118 - mean_squared_error: 0.0118\n",
      "Epoch 11/15\n",
      "35/35 [==============================] - 6s 174ms/step - loss: 0.0150 - mean_squared_error: 0.0150\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with the EarlyStopping callback\n",
    "history = model.fit(X, Y, batch_size=25, epochs=15, shuffle=True, verbose=1, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('emointjoy.h5','/Home')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "loaded_model = load_model('emointjoy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pd.read_csv(\"Desktop/emoint tweet/anger-ratings-0to1.test.target.txt\", delimiter='\\t', header=None)\n",
    "test.columns = ['Id', 'tweet', 'emotion', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10941</td>\n",
       "      <td>At the point today where if someone says somet...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10942</td>\n",
       "      <td>@CorningFootball  IT'S GAME DAY!!!!      T MIN...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10943</td>\n",
       "      <td>This game has pissed me off more than any othe...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10944</td>\n",
       "      <td>@spamvicious I've just found out it's Candice ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10945</td>\n",
       "      <td>@moocowward @mrsajhargreaves @Melly77 @GaryBar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>11696</td>\n",
       "      <td>@ggreenwald What if the supposed animosity is ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>11697</td>\n",
       "      <td>Will BYU's offense score 24+ vs WVU?</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>11698</td>\n",
       "      <td>Id love 2 c Gyimah in action but his coach is ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>11699</td>\n",
       "      <td>Forgiving means operating with God's spirit &amp;a...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>11700</td>\n",
       "      <td>i've got a lot of tokens saved up and i wanna ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion score\n",
       "0    10941  At the point today where if someone says somet...   anger  NONE\n",
       "1    10942  @CorningFootball  IT'S GAME DAY!!!!      T MIN...   anger  NONE\n",
       "2    10943  This game has pissed me off more than any othe...   anger  NONE\n",
       "3    10944  @spamvicious I've just found out it's Candice ...   anger  NONE\n",
       "4    10945  @moocowward @mrsajhargreaves @Melly77 @GaryBar...   anger  NONE\n",
       "..     ...                                                ...     ...   ...\n",
       "755  11696  @ggreenwald What if the supposed animosity is ...   anger  NONE\n",
       "756  11697               Will BYU's offense score 24+ vs WVU?   anger  NONE\n",
       "757  11698  Id love 2 c Gyimah in action but his coach is ...   anger  NONE\n",
       "758  11699  Forgiving means operating with God's spirit &a...   anger  NONE\n",
       "759  11700  i've got a lot of tokens saved up and i wanna ...   anger  NONE\n",
       "\n",
       "[760 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= test.drop(\"score\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10941</td>\n",
       "      <td>At the point today where if someone says somet...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10942</td>\n",
       "      <td>@CorningFootball  IT'S GAME DAY!!!!      T MIN...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10943</td>\n",
       "      <td>This game has pissed me off more than any othe...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10944</td>\n",
       "      <td>@spamvicious I've just found out it's Candice ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10945</td>\n",
       "      <td>@moocowward @mrsajhargreaves @Melly77 @GaryBar...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>11696</td>\n",
       "      <td>@ggreenwald What if the supposed animosity is ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>11697</td>\n",
       "      <td>Will BYU's offense score 24+ vs WVU?</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>11698</td>\n",
       "      <td>Id love 2 c Gyimah in action but his coach is ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>11699</td>\n",
       "      <td>Forgiving means operating with God's spirit &amp;a...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>11700</td>\n",
       "      <td>i've got a lot of tokens saved up and i wanna ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion\n",
       "0    10941  At the point today where if someone says somet...   anger\n",
       "1    10942  @CorningFootball  IT'S GAME DAY!!!!      T MIN...   anger\n",
       "2    10943  This game has pissed me off more than any othe...   anger\n",
       "3    10944  @spamvicious I've just found out it's Candice ...   anger\n",
       "4    10945  @moocowward @mrsajhargreaves @Melly77 @GaryBar...   anger\n",
       "..     ...                                                ...     ...\n",
       "755  11696  @ggreenwald What if the supposed animosity is ...   anger\n",
       "756  11697               Will BYU's offense score 24+ vs WVU?   anger\n",
       "757  11698  Id love 2 c Gyimah in action but his coach is ...   anger\n",
       "758  11699  Forgiving means operating with God's spirit &a...   anger\n",
       "759  11700  i've got a lot of tokens saved up and i wanna ...   anger\n",
       "\n",
       "[760 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", tweet)\n",
    "    \n",
    "    return tweet\n",
    "test['tweet'] = test['tweet'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10941</td>\n",
       "      <td>at the point today where if someone says somet...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10942</td>\n",
       "      <td>@corningfootball  it's game day!!!!      t min...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10943</td>\n",
       "      <td>this game has pissed me off more than any othe...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10944</td>\n",
       "      <td>@spamvicious i've just found out it's candice ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10945</td>\n",
       "      <td>@moocowward @mrsajhargreaves @melly77 @garybar...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>11696</td>\n",
       "      <td>@ggreenwald what if the supposed animosity is ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>11697</td>\n",
       "      <td>will byu's offense score 24+ vs wvu?</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>11698</td>\n",
       "      <td>id love 2 c gyimah in action but his coach is ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>11699</td>\n",
       "      <td>forgiving means operating with god's spirit &amp;a...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>11700</td>\n",
       "      <td>i've got a lot of tokens saved up and i wanna ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion\n",
       "0    10941  at the point today where if someone says somet...   anger\n",
       "1    10942  @corningfootball  it's game day!!!!      t min...   anger\n",
       "2    10943  this game has pissed me off more than any othe...   anger\n",
       "3    10944  @spamvicious i've just found out it's candice ...   anger\n",
       "4    10945  @moocowward @mrsajhargreaves @melly77 @garybar...   anger\n",
       "..     ...                                                ...     ...\n",
       "755  11696  @ggreenwald what if the supposed animosity is ...   anger\n",
       "756  11697               will byu's offense score 24+ vs wvu?   anger\n",
       "757  11698  id love 2 c gyimah in action but his coach is ...   anger\n",
       "758  11699  forgiving means operating with god's spirit &a...   anger\n",
       "759  11700  i've got a lot of tokens saved up and i wanna ...   anger\n",
       "\n",
       "[760 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10941</td>\n",
       "      <td>at the point today where if someone says somet...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10942</td>\n",
       "      <td>it's game day!!!!      t minus 14:30  #relen...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10943</td>\n",
       "      <td>this game has pissed me off more than any othe...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10944</td>\n",
       "      <td>i've just found out it's candice and not cand...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10945</td>\n",
       "      <td>if he can't come to my mum'a 60th after 25...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>11696</td>\n",
       "      <td>what if the supposed animosity is all bullshi...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>11697</td>\n",
       "      <td>will byu's offense score 24+ vs wvu?</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>11698</td>\n",
       "      <td>id love 2 c gyimah in action but his coach is ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>11699</td>\n",
       "      <td>forgiving means operating with god's spirit &amp;a...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>11700</td>\n",
       "      <td>i've got a lot of tokens saved up and i wanna ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion\n",
       "0    10941  at the point today where if someone says somet...   anger\n",
       "1    10942    it's game day!!!!      t minus 14:30  #relen...   anger\n",
       "2    10943  this game has pissed me off more than any othe...   anger\n",
       "3    10944   i've just found out it's candice and not cand...   anger\n",
       "4    10945      if he can't come to my mum'a 60th after 25...   anger\n",
       "..     ...                                                ...     ...\n",
       "755  11696   what if the supposed animosity is all bullshi...   anger\n",
       "756  11697               will byu's offense score 24+ vs wvu?   anger\n",
       "757  11698  id love 2 c gyimah in action but his coach is ...   anger\n",
       "758  11699  forgiving means operating with god's spirit &a...   anger\n",
       "759  11700  i've got a lot of tokens saved up and i wanna ...   anger\n",
       "\n",
       "[760 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_mentions(tweet):\n",
    "    return re.sub(r'@\\w+', '', tweet)\n",
    "\n",
    "test['tweet'] = test['tweet'].apply(remove_mentions)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s#@]', '', text)  # Remove all non-word characters except # and @ symbols\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "test['tweet'] = test['tweet'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10941</td>\n",
       "      <td>at the point today where if someone says somet...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10942</td>\n",
       "      <td>its game day t minus #relentless</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10943</td>\n",
       "      <td>this game has pissed me off more than any othe...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10944</td>\n",
       "      <td>ive just found out its candice and not candace...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10945</td>\n",
       "      <td>if he cant come to my muma th after k tweets t...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>11696</td>\n",
       "      <td>what if the supposed animosity is all bullshit...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>11697</td>\n",
       "      <td>will byus offense score vs wvu</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>11698</td>\n",
       "      <td>id love c gyimah in action but his coach is ho...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>11699</td>\n",
       "      <td>forgiving means operating with gods spirit amp...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>11700</td>\n",
       "      <td>ive got a lot of tokens saved up and i wanna s...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion\n",
       "0    10941  at the point today where if someone says somet...   anger\n",
       "1    10942                   its game day t minus #relentless   anger\n",
       "2    10943  this game has pissed me off more than any othe...   anger\n",
       "3    10944  ive just found out its candice and not candace...   anger\n",
       "4    10945  if he cant come to my muma th after k tweets t...   anger\n",
       "..     ...                                                ...     ...\n",
       "755  11696  what if the supposed animosity is all bullshit...   anger\n",
       "756  11697                     will byus offense score vs wvu   anger\n",
       "757  11698  id love c gyimah in action but his coach is ho...   anger\n",
       "758  11699  forgiving means operating with gods spirit amp...   anger\n",
       "759  11700  ive got a lot of tokens saved up and i wanna s...   anger\n",
       "\n",
       "[760 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emoji(tweet):\n",
    "    text = emoji.demojize(tweet)\n",
    "    return text\n",
    "\n",
    "test['tweet'] = test['tweet'].apply(convert_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweets(tweet):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    return tokenizer.tokenize(tweet)\n",
    "\n",
    "test['tweet'] = test['tweet'].apply(tokenize_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10941</td>\n",
       "      <td>[at, the, point, today, where, if, someone, sa...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10942</td>\n",
       "      <td>[its, game, day, t, minus, #relentless]</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10943</td>\n",
       "      <td>[this, game, has, pissed, me, off, more, than,...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10944</td>\n",
       "      <td>[ive, just, found, out, its, candice, and, not...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10945</td>\n",
       "      <td>[if, he, cant, come, to, my, muma, th, after, ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>11696</td>\n",
       "      <td>[what, if, the, supposed, animosity, is, all, ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>11697</td>\n",
       "      <td>[will, byus, offense, score, vs, wvu]</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>11698</td>\n",
       "      <td>[id, love, c, gyimah, in, action, but, his, co...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>11699</td>\n",
       "      <td>[forgiving, means, operating, with, gods, spir...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>11700</td>\n",
       "      <td>[ive, got, a, lot, of, tokens, saved, up, and,...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion\n",
       "0    10941  [at, the, point, today, where, if, someone, sa...   anger\n",
       "1    10942            [its, game, day, t, minus, #relentless]   anger\n",
       "2    10943  [this, game, has, pissed, me, off, more, than,...   anger\n",
       "3    10944  [ive, just, found, out, its, candice, and, not...   anger\n",
       "4    10945  [if, he, cant, come, to, my, muma, th, after, ...   anger\n",
       "..     ...                                                ...     ...\n",
       "755  11696  [what, if, the, supposed, animosity, is, all, ...   anger\n",
       "756  11697              [will, byus, offense, score, vs, wvu]   anger\n",
       "757  11698  [id, love, c, gyimah, in, action, but, his, co...   anger\n",
       "758  11699  [forgiving, means, operating, with, gods, spir...   anger\n",
       "759  11700  [ive, got, a, lot, of, tokens, saved, up, and,...   anger\n",
       "\n",
       "[760 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop_words = [\n",
    "    'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'he', 'in', 'is', 'it', 'its',\n",
    "    'of', 'on', 'that', 'the', 'to', 'was', 'were', 'will', 'with', 'i', 'you', 'your', 'so', 'this', 'all',\n",
    "    'am', 'or', 'but', 'if', 'my', 'me', 'we', 'us', 'our', 'we', 'up', 'down', 'out', 'just', 'how', 'why',\n",
    "    'when', 'where', 'here', 'there', 'about', 'more', 'most', 'some', 'any', 'few', 'many', 'much', 'not',\n",
    "    'only', 'other', 'same', 'such', 'no', 'nor', 'too', 'very', 'can', 'cannot', 'could', 'should', 'would',\n",
    "    'might', 'must', 'shall', 'will', 'isn', 'hasn', 'doesn', 'haven', 'didn', 'hadn', 'wasn', 'weren',\n",
    "    'wouldn', 'shouldn', 'ain', 'aren', 'ma'\n",
    "]\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [token for token in tokens if len(token) > 1 and token.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "test['tweet'] = test['tweet'].apply(remove_stopwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10941</td>\n",
       "      <td>[point, today, someone, says, something, remot...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10942</td>\n",
       "      <td>[game, day, minus, #relentless]</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10943</td>\n",
       "      <td>[game, pissed, off, than, game, year, blood, b...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10944</td>\n",
       "      <td>[ive, found, candice, candace, she, pout, she,...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10945</td>\n",
       "      <td>[cant, come, muma, th, after, tweets, then, #s...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>11696</td>\n",
       "      <td>[what, supposed, animosity, bullshit, con, ira...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>11697</td>\n",
       "      <td>[byus, offense, score, vs, wvu]</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>11698</td>\n",
       "      <td>[id, love, gyimah, action, his, coach, holding...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>11699</td>\n",
       "      <td>[forgiving, means, operating, gods, spirit, am...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>11700</td>\n",
       "      <td>[ive, got, lot, tokens, saved, wanna, spam, ev...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion\n",
       "0    10941  [point, today, someone, says, something, remot...   anger\n",
       "1    10942                    [game, day, minus, #relentless]   anger\n",
       "2    10943  [game, pissed, off, than, game, year, blood, b...   anger\n",
       "3    10944  [ive, found, candice, candace, she, pout, she,...   anger\n",
       "4    10945  [cant, come, muma, th, after, tweets, then, #s...   anger\n",
       "..     ...                                                ...     ...\n",
       "755  11696  [what, supposed, animosity, bullshit, con, ira...   anger\n",
       "756  11697                    [byus, offense, score, vs, wvu]   anger\n",
       "757  11698  [id, love, gyimah, action, his, coach, holding...   anger\n",
       "758  11699  [forgiving, means, operating, gods, spirit, am...   anger\n",
       "759  11700  [ive, got, lot, tokens, saved, wanna, spam, ev...   anger\n",
       "\n",
       "[760 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "def extract_features(tweet):\n",
    "    \n",
    "    tokenized_text = ' '.join(tweet)\n",
    "    \n",
    "    \n",
    "    input_ids = torch.tensor(tokenizer.encode(tokenized_text, add_special_tokens=True)).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    \n",
    " \n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    \n",
    "    features = last_hidden_states.squeeze(0).numpy()\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "test['features'] = test['tweet'].apply(extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 768)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"features\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "features = test['features'].tolist()\n",
    "\n",
    "padded_features = pad_sequences(features, padding='post')\n",
    "\n",
    "\n",
    "padded_df = test.copy()\n",
    "padded_df['features'] = padded_features.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input feature shape: (760, 43, 768)\n"
     ]
    }
   ],
   "source": [
    "X_test= np.stack(padded_df['features'])\n",
    "\n",
    "\n",
    "print('Input feature shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(760, 40, 768)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_sequence_length = 40  \n",
    "truncated_test_data = X_test[:, :max_sequence_length, :]\n",
    "\n",
    "print(truncated_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(truncated_test_data, (760, 40 * 768))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(760, 30720)\n"
     ]
    }
   ],
   "source": [
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = loaded_model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.46497917]\n",
      " [0.38698965]\n",
      " [0.5187774 ]\n",
      " [0.39725143]\n",
      " [0.462135  ]\n",
      " [0.45312154]\n",
      " [0.34976918]\n",
      " [0.5283527 ]\n",
      " [0.42789316]\n",
      " [0.3795662 ]\n",
      " [0.563908  ]\n",
      " [0.6068222 ]\n",
      " [0.4150099 ]\n",
      " [0.5046943 ]\n",
      " [0.49170896]\n",
      " [0.42456302]\n",
      " [0.4110153 ]\n",
      " [0.40576395]\n",
      " [0.49175787]\n",
      " [0.38657203]\n",
      " [0.31104782]\n",
      " [0.33245912]\n",
      " [0.44371617]\n",
      " [0.4607534 ]\n",
      " [0.42632976]\n",
      " [0.41070804]\n",
      " [0.38059744]\n",
      " [0.35823944]\n",
      " [0.42189983]\n",
      " [0.4135949 ]\n",
      " [0.44437745]\n",
      " [0.4748812 ]\n",
      " [0.35356024]\n",
      " [0.36958903]\n",
      " [0.41419348]\n",
      " [0.43952844]\n",
      " [0.28582957]\n",
      " [0.32020888]\n",
      " [0.4225161 ]\n",
      " [0.38726926]\n",
      " [0.49004155]\n",
      " [0.42853186]\n",
      " [0.44773194]\n",
      " [0.5151202 ]\n",
      " [0.43898067]\n",
      " [0.43224892]\n",
      " [0.35471418]\n",
      " [0.38577247]\n",
      " [0.40190223]\n",
      " [0.4090554 ]\n",
      " [0.4838528 ]\n",
      " [0.39377698]\n",
      " [0.39862087]\n",
      " [0.46614775]\n",
      " [0.46970466]\n",
      " [0.31986123]\n",
      " [0.31711417]\n",
      " [0.42101976]\n",
      " [0.46423256]\n",
      " [0.43658343]\n",
      " [0.52208716]\n",
      " [0.4565932 ]\n",
      " [0.41176328]\n",
      " [0.4876761 ]\n",
      " [0.47402802]\n",
      " [0.42735973]\n",
      " [0.43874735]\n",
      " [0.4544681 ]\n",
      " [0.3887739 ]\n",
      " [0.4961859 ]\n",
      " [0.47599724]\n",
      " [0.4583831 ]\n",
      " [0.4647756 ]\n",
      " [0.49569157]\n",
      " [0.49319363]\n",
      " [0.43478003]\n",
      " [0.41131237]\n",
      " [0.5019737 ]\n",
      " [0.40296385]\n",
      " [0.39725235]\n",
      " [0.46347767]\n",
      " [0.46502814]\n",
      " [0.38267276]\n",
      " [0.3216705 ]\n",
      " [0.40949246]\n",
      " [0.4719717 ]\n",
      " [0.5697079 ]\n",
      " [0.40246397]\n",
      " [0.46274826]\n",
      " [0.42942622]\n",
      " [0.42584082]\n",
      " [0.41006345]\n",
      " [0.3708832 ]\n",
      " [0.44324416]\n",
      " [0.43237466]\n",
      " [0.5086383 ]\n",
      " [0.4920899 ]\n",
      " [0.4169805 ]\n",
      " [0.44021535]\n",
      " [0.3589659 ]\n",
      " [0.4502752 ]\n",
      " [0.3846525 ]\n",
      " [0.4284058 ]\n",
      " [0.5625239 ]\n",
      " [0.39542237]\n",
      " [0.38074008]\n",
      " [0.3985664 ]\n",
      " [0.4747793 ]\n",
      " [0.4182466 ]\n",
      " [0.40275973]\n",
      " [0.38901916]\n",
      " [0.42356533]\n",
      " [0.41970047]\n",
      " [0.40957278]\n",
      " [0.43880302]\n",
      " [0.4230416 ]\n",
      " [0.45003638]\n",
      " [0.40813687]\n",
      " [0.4513153 ]\n",
      " [0.39655256]\n",
      " [0.384088  ]\n",
      " [0.35338056]\n",
      " [0.47408757]\n",
      " [0.29798067]\n",
      " [0.4055071 ]\n",
      " [0.4710249 ]\n",
      " [0.40628573]\n",
      " [0.46280643]\n",
      " [0.4479421 ]\n",
      " [0.45425853]\n",
      " [0.46364006]\n",
      " [0.45047775]\n",
      " [0.38150492]\n",
      " [0.43213156]\n",
      " [0.38011175]\n",
      " [0.4254465 ]\n",
      " [0.51718926]\n",
      " [0.4512815 ]\n",
      " [0.4458838 ]\n",
      " [0.42255917]\n",
      " [0.41428074]\n",
      " [0.48446253]\n",
      " [0.4711901 ]\n",
      " [0.4417558 ]\n",
      " [0.4610613 ]\n",
      " [0.39364752]\n",
      " [0.44807634]\n",
      " [0.5201798 ]\n",
      " [0.3846738 ]\n",
      " [0.44813374]\n",
      " [0.43247938]\n",
      " [0.4174576 ]\n",
      " [0.4072572 ]\n",
      " [0.41357875]\n",
      " [0.46769008]\n",
      " [0.49252465]\n",
      " [0.50851756]\n",
      " [0.4892802 ]\n",
      " [0.3632647 ]\n",
      " [0.27164647]\n",
      " [0.38494685]\n",
      " [0.48665494]\n",
      " [0.42839274]\n",
      " [0.43841076]\n",
      " [0.40395272]\n",
      " [0.52248716]\n",
      " [0.45972535]\n",
      " [0.48685956]\n",
      " [0.48059782]\n",
      " [0.41211155]\n",
      " [0.47230873]\n",
      " [0.42667213]\n",
      " [0.4804714 ]\n",
      " [0.40176407]\n",
      " [0.43783128]\n",
      " [0.33171275]\n",
      " [0.31340584]\n",
      " [0.52705926]\n",
      " [0.4481048 ]\n",
      " [0.5212448 ]\n",
      " [0.41651675]\n",
      " [0.43176034]\n",
      " [0.48422948]\n",
      " [0.48433018]\n",
      " [0.39866164]\n",
      " [0.49580485]\n",
      " [0.4752623 ]\n",
      " [0.46631384]\n",
      " [0.33993298]\n",
      " [0.5523942 ]\n",
      " [0.43500772]\n",
      " [0.48305643]\n",
      " [0.5013227 ]\n",
      " [0.39499918]\n",
      " [0.4219608 ]\n",
      " [0.42043218]\n",
      " [0.3451364 ]\n",
      " [0.42903695]\n",
      " [0.47363457]\n",
      " [0.4193493 ]\n",
      " [0.3651947 ]\n",
      " [0.47268853]\n",
      " [0.48368454]\n",
      " [0.43866324]\n",
      " [0.30443627]\n",
      " [0.43241698]\n",
      " [0.39171502]\n",
      " [0.3997554 ]\n",
      " [0.4021363 ]\n",
      " [0.33842954]\n",
      " [0.40139356]\n",
      " [0.45794162]\n",
      " [0.4182799 ]\n",
      " [0.4124077 ]\n",
      " [0.48461196]\n",
      " [0.35629722]\n",
      " [0.39539698]\n",
      " [0.4858495 ]\n",
      " [0.40226915]\n",
      " [0.51327807]\n",
      " [0.5037699 ]\n",
      " [0.3867651 ]\n",
      " [0.41488788]\n",
      " [0.43045214]\n",
      " [0.45817077]\n",
      " [0.5083232 ]\n",
      " [0.4124295 ]\n",
      " [0.2919271 ]\n",
      " [0.45828226]\n",
      " [0.4966691 ]\n",
      " [0.4588339 ]\n",
      " [0.4280518 ]\n",
      " [0.39084128]\n",
      " [0.49349603]\n",
      " [0.553344  ]\n",
      " [0.43753526]\n",
      " [0.3208137 ]\n",
      " [0.54308844]\n",
      " [0.42313176]\n",
      " [0.3285599 ]\n",
      " [0.5076182 ]\n",
      " [0.42197576]\n",
      " [0.5426455 ]\n",
      " [0.4594391 ]\n",
      " [0.5034072 ]\n",
      " [0.4383783 ]\n",
      " [0.42502174]\n",
      " [0.33973387]\n",
      " [0.45948318]\n",
      " [0.46849224]\n",
      " [0.44814143]\n",
      " [0.40539417]\n",
      " [0.47815132]\n",
      " [0.4797046 ]\n",
      " [0.47242785]\n",
      " [0.46228948]\n",
      " [0.43119857]\n",
      " [0.2692851 ]\n",
      " [0.27895385]\n",
      " [0.4873083 ]\n",
      " [0.46707416]\n",
      " [0.41589427]\n",
      " [0.35485736]\n",
      " [0.37817472]\n",
      " [0.3073386 ]\n",
      " [0.32245648]\n",
      " [0.32302248]\n",
      " [0.43451947]\n",
      " [0.47363457]\n",
      " [0.5013284 ]\n",
      " [0.47162554]\n",
      " [0.47316602]\n",
      " [0.4768125 ]\n",
      " [0.47246367]\n",
      " [0.47433105]\n",
      " [0.394475  ]\n",
      " [0.41798744]\n",
      " [0.48316902]\n",
      " [0.5297467 ]\n",
      " [0.4008539 ]\n",
      " [0.44401327]\n",
      " [0.470499  ]\n",
      " [0.45860752]\n",
      " [0.34319136]\n",
      " [0.39997464]\n",
      " [0.4333916 ]\n",
      " [0.45000315]\n",
      " [0.4183034 ]\n",
      " [0.39923683]\n",
      " [0.43425912]\n",
      " [0.45933008]\n",
      " [0.4120766 ]\n",
      " [0.38892213]\n",
      " [0.43479583]\n",
      " [0.43509316]\n",
      " [0.39449674]\n",
      " [0.39258954]\n",
      " [0.3747438 ]\n",
      " [0.41084707]\n",
      " [0.52312815]\n",
      " [0.4595038 ]\n",
      " [0.4949182 ]\n",
      " [0.46607876]\n",
      " [0.40298274]\n",
      " [0.49646524]\n",
      " [0.48948768]\n",
      " [0.3861736 ]\n",
      " [0.4911745 ]\n",
      " [0.36854413]\n",
      " [0.41539684]\n",
      " [0.38754013]\n",
      " [0.35267314]\n",
      " [0.44779313]\n",
      " [0.42034146]\n",
      " [0.4281327 ]\n",
      " [0.48207876]\n",
      " [0.35259697]\n",
      " [0.5870961 ]\n",
      " [0.4025705 ]\n",
      " [0.3309985 ]\n",
      " [0.39302942]\n",
      " [0.4994417 ]\n",
      " [0.464469  ]\n",
      " [0.38973865]\n",
      " [0.4213399 ]\n",
      " [0.40128794]\n",
      " [0.45088062]\n",
      " [0.4469361 ]\n",
      " [0.43938085]\n",
      " [0.5230448 ]\n",
      " [0.5120148 ]\n",
      " [0.3346375 ]\n",
      " [0.40459314]\n",
      " [0.46864802]\n",
      " [0.45350364]\n",
      " [0.43818572]\n",
      " [0.35017815]\n",
      " [0.43203446]\n",
      " [0.3971315 ]\n",
      " [0.48143914]\n",
      " [0.43679944]\n",
      " [0.38856587]\n",
      " [0.3924497 ]\n",
      " [0.41949037]\n",
      " [0.40454507]\n",
      " [0.404786  ]\n",
      " [0.44561633]\n",
      " [0.36384162]\n",
      " [0.46670952]\n",
      " [0.46631378]\n",
      " [0.32209826]\n",
      " [0.3934414 ]\n",
      " [0.39386946]\n",
      " [0.4190745 ]\n",
      " [0.50567496]\n",
      " [0.34057465]\n",
      " [0.37646922]\n",
      " [0.44004706]\n",
      " [0.43789917]\n",
      " [0.40286937]\n",
      " [0.30437624]\n",
      " [0.32283297]\n",
      " [0.38084003]\n",
      " [0.46298867]\n",
      " [0.45634806]\n",
      " [0.42837694]\n",
      " [0.4202247 ]\n",
      " [0.41853514]\n",
      " [0.3946812 ]\n",
      " [0.47769627]\n",
      " [0.51269126]\n",
      " [0.45018473]\n",
      " [0.422452  ]\n",
      " [0.37879643]\n",
      " [0.49817976]\n",
      " [0.47461185]\n",
      " [0.48055243]\n",
      " [0.31928942]\n",
      " [0.32932374]\n",
      " [0.41858074]\n",
      " [0.41513973]\n",
      " [0.42280582]\n",
      " [0.43031237]\n",
      " [0.44227186]\n",
      " [0.42263433]\n",
      " [0.42791522]\n",
      " [0.51620275]\n",
      " [0.47220817]\n",
      " [0.50305444]\n",
      " [0.47104058]\n",
      " [0.3941227 ]\n",
      " [0.3309971 ]\n",
      " [0.4181684 ]\n",
      " [0.4977326 ]\n",
      " [0.51731354]\n",
      " [0.43550262]\n",
      " [0.46488178]\n",
      " [0.36829638]\n",
      " [0.29519448]\n",
      " [0.44235155]\n",
      " [0.49129686]\n",
      " [0.4049843 ]\n",
      " [0.38549742]\n",
      " [0.5045801 ]\n",
      " [0.48542133]\n",
      " [0.4039652 ]\n",
      " [0.32639506]\n",
      " [0.31344855]\n",
      " [0.45894966]\n",
      " [0.37039798]\n",
      " [0.4739627 ]\n",
      " [0.4329358 ]\n",
      " [0.33619812]\n",
      " [0.4516611 ]\n",
      " [0.40131494]\n",
      " [0.43643293]\n",
      " [0.46799466]\n",
      " [0.4376968 ]\n",
      " [0.37193772]\n",
      " [0.5012922 ]\n",
      " [0.4213317 ]\n",
      " [0.40479186]\n",
      " [0.393428  ]\n",
      " [0.4416217 ]\n",
      " [0.50295126]\n",
      " [0.5139953 ]\n",
      " [0.38241538]\n",
      " [0.5300805 ]\n",
      " [0.39790812]\n",
      " [0.37846714]\n",
      " [0.48167646]\n",
      " [0.45436063]\n",
      " [0.3064686 ]\n",
      " [0.43221086]\n",
      " [0.3425454 ]\n",
      " [0.3879558 ]\n",
      " [0.4437041 ]\n",
      " [0.3781672 ]\n",
      " [0.41463283]\n",
      " [0.40329623]\n",
      " [0.47989962]\n",
      " [0.3679077 ]\n",
      " [0.45477068]\n",
      " [0.54448867]\n",
      " [0.41341057]\n",
      " [0.4289203 ]\n",
      " [0.41930094]\n",
      " [0.4920285 ]\n",
      " [0.4655709 ]\n",
      " [0.50375456]\n",
      " [0.38061392]\n",
      " [0.36450112]\n",
      " [0.5067477 ]\n",
      " [0.47147912]\n",
      " [0.5548498 ]\n",
      " [0.4436254 ]\n",
      " [0.45977587]\n",
      " [0.45115677]\n",
      " [0.43704125]\n",
      " [0.44856542]\n",
      " [0.4218901 ]\n",
      " [0.38879982]\n",
      " [0.54193854]\n",
      " [0.40222827]\n",
      " [0.4513331 ]\n",
      " [0.35774323]\n",
      " [0.4315706 ]\n",
      " [0.3716978 ]\n",
      " [0.42332366]\n",
      " [0.40494603]\n",
      " [0.5023223 ]\n",
      " [0.44093987]\n",
      " [0.40874058]\n",
      " [0.33508992]\n",
      " [0.6068222 ]\n",
      " [0.47836715]\n",
      " [0.45009333]\n",
      " [0.38246778]\n",
      " [0.42008418]\n",
      " [0.482349  ]\n",
      " [0.52511823]\n",
      " [0.44048786]\n",
      " [0.514773  ]\n",
      " [0.44553408]\n",
      " [0.39385602]\n",
      " [0.36581883]\n",
      " [0.43330345]\n",
      " [0.44725963]\n",
      " [0.49459678]\n",
      " [0.42625102]\n",
      " [0.34372172]\n",
      " [0.4342375 ]\n",
      " [0.3910161 ]\n",
      " [0.42579967]\n",
      " [0.46707374]\n",
      " [0.36765578]\n",
      " [0.38735905]\n",
      " [0.5120894 ]\n",
      " [0.45460984]\n",
      " [0.46809733]\n",
      " [0.32772323]\n",
      " [0.31933552]\n",
      " [0.3724154 ]\n",
      " [0.32082433]\n",
      " [0.5012922 ]\n",
      " [0.38948202]\n",
      " [0.3437935 ]\n",
      " [0.44949153]\n",
      " [0.4335226 ]\n",
      " [0.42338803]\n",
      " [0.4888745 ]\n",
      " [0.45170936]\n",
      " [0.36974123]\n",
      " [0.46362895]\n",
      " [0.40215337]\n",
      " [0.3390174 ]\n",
      " [0.4462688 ]\n",
      " [0.4314368 ]\n",
      " [0.40777907]\n",
      " [0.50134945]\n",
      " [0.40657815]\n",
      " [0.45123783]\n",
      " [0.4628082 ]\n",
      " [0.47410002]\n",
      " [0.4754944 ]\n",
      " [0.46233833]\n",
      " [0.44850296]\n",
      " [0.3655546 ]\n",
      " [0.39594373]\n",
      " [0.4961031 ]\n",
      " [0.5606029 ]\n",
      " [0.34886208]\n",
      " [0.4243893 ]\n",
      " [0.45308462]\n",
      " [0.44299075]\n",
      " [0.49869004]\n",
      " [0.5236415 ]\n",
      " [0.3821056 ]\n",
      " [0.37186113]\n",
      " [0.44495052]\n",
      " [0.49492434]\n",
      " [0.46615925]\n",
      " [0.338456  ]\n",
      " [0.3925211 ]\n",
      " [0.45024696]\n",
      " [0.3629016 ]\n",
      " [0.39312425]\n",
      " [0.40507266]\n",
      " [0.30483055]\n",
      " [0.4163705 ]\n",
      " [0.42008957]\n",
      " [0.36540493]\n",
      " [0.49794766]\n",
      " [0.33119285]\n",
      " [0.31501773]\n",
      " [0.39635816]\n",
      " [0.44302163]\n",
      " [0.4601368 ]\n",
      " [0.49007004]\n",
      " [0.43119073]\n",
      " [0.4416118 ]\n",
      " [0.48846504]\n",
      " [0.37437534]\n",
      " [0.43672538]\n",
      " [0.37826046]\n",
      " [0.43163714]\n",
      " [0.49975753]\n",
      " [0.45996436]\n",
      " [0.27286896]\n",
      " [0.28302357]\n",
      " [0.51837504]\n",
      " [0.53384316]\n",
      " [0.38431853]\n",
      " [0.45743766]\n",
      " [0.39470944]\n",
      " [0.49769786]\n",
      " [0.3798351 ]\n",
      " [0.49552798]\n",
      " [0.55744916]\n",
      " [0.37269208]\n",
      " [0.4555035 ]\n",
      " [0.3605508 ]\n",
      " [0.43007097]\n",
      " [0.44595924]\n",
      " [0.35523757]\n",
      " [0.40794337]\n",
      " [0.4206148 ]\n",
      " [0.4396135 ]\n",
      " [0.412711  ]\n",
      " [0.35499972]\n",
      " [0.44682512]\n",
      " [0.3481612 ]\n",
      " [0.37642696]\n",
      " [0.41070822]\n",
      " [0.40888676]\n",
      " [0.50743985]\n",
      " [0.33547178]\n",
      " [0.44875315]\n",
      " [0.4836054 ]\n",
      " [0.39697704]\n",
      " [0.34987232]\n",
      " [0.47345525]\n",
      " [0.51307374]\n",
      " [0.3755301 ]\n",
      " [0.45986778]\n",
      " [0.43500045]\n",
      " [0.4358718 ]\n",
      " [0.34267804]\n",
      " [0.39515802]\n",
      " [0.41176066]\n",
      " [0.49015445]\n",
      " [0.46909192]\n",
      " [0.32801032]\n",
      " [0.49228847]\n",
      " [0.41939804]\n",
      " [0.5007435 ]\n",
      " [0.5378544 ]\n",
      " [0.4374074 ]\n",
      " [0.45090058]\n",
      " [0.273453  ]\n",
      " [0.36876255]\n",
      " [0.3537674 ]\n",
      " [0.40907398]\n",
      " [0.40920505]\n",
      " [0.42973605]\n",
      " [0.45239684]\n",
      " [0.42775238]\n",
      " [0.45933738]\n",
      " [0.41215023]\n",
      " [0.74869853]\n",
      " [0.46697375]\n",
      " [0.40986624]\n",
      " [0.34959078]\n",
      " [0.46957794]\n",
      " [0.355935  ]\n",
      " [0.4444449 ]\n",
      " [0.4594969 ]\n",
      " [0.47870922]\n",
      " [0.55598813]\n",
      " [0.41083974]\n",
      " [0.46164075]\n",
      " [0.39503106]\n",
      " [0.3769692 ]\n",
      " [0.3487138 ]\n",
      " [0.328624  ]\n",
      " [0.47001415]\n",
      " [0.40426666]\n",
      " [0.4331439 ]\n",
      " [0.44973704]\n",
      " [0.44721422]\n",
      " [0.5067572 ]\n",
      " [0.37852886]\n",
      " [0.49396458]\n",
      " [0.4623233 ]\n",
      " [0.45541206]\n",
      " [0.3808094 ]\n",
      " [0.42964607]\n",
      " [0.36996025]\n",
      " [0.3704318 ]\n",
      " [0.3478258 ]\n",
      " [0.43344983]\n",
      " [0.45831534]\n",
      " [0.4420897 ]\n",
      " [0.39483625]\n",
      " [0.42267245]\n",
      " [0.4213321 ]\n",
      " [0.47154763]\n",
      " [0.39141828]\n",
      " [0.48845926]\n",
      " [0.38220558]\n",
      " [0.51602125]\n",
      " [0.44388232]\n",
      " [0.5039418 ]\n",
      " [0.4450023 ]\n",
      " [0.5234794 ]\n",
      " [0.39651847]\n",
      " [0.47895542]\n",
      " [0.50513417]\n",
      " [0.4433259 ]\n",
      " [0.48446387]\n",
      " [0.4372079 ]\n",
      " [0.472144  ]\n",
      " [0.33489153]\n",
      " [0.45810544]\n",
      " [0.46338588]\n",
      " [0.46417338]\n",
      " [0.39241973]\n",
      " [0.49285707]\n",
      " [0.5235346 ]\n",
      " [0.41830987]\n",
      " [0.46175447]\n",
      " [0.43932137]\n",
      " [0.39170176]\n",
      " [0.33668193]\n",
      " [0.38138136]\n",
      " [0.42296168]\n",
      " [0.31967208]\n",
      " [0.5190447 ]\n",
      " [0.50376946]\n",
      " [0.37385815]\n",
      " [0.49934074]\n",
      " [0.39089575]\n",
      " [0.39027894]\n",
      " [0.48192707]\n",
      " [0.40987688]\n",
      " [0.448971  ]\n",
      " [0.39124283]\n",
      " [0.4387382 ]\n",
      " [0.43605298]\n",
      " [0.48214582]\n",
      " [0.42821315]\n",
      " [0.46965775]\n",
      " [0.41608006]\n",
      " [0.4134992 ]\n",
      " [0.4100311 ]\n",
      " [0.4462719 ]\n",
      " [0.36697173]\n",
      " [0.3844091 ]\n",
      " [0.4054273 ]\n",
      " [0.4296948 ]\n",
      " [0.46956307]\n",
      " [0.4606891 ]\n",
      " [0.45876917]\n",
      " [0.40241   ]\n",
      " [0.3254388 ]\n",
      " [0.43164834]\n",
      " [0.38506058]\n",
      " [0.44415373]\n",
      " [0.41661802]\n",
      " [0.40962926]\n",
      " [0.43753687]\n",
      " [0.38731796]\n",
      " [0.4142742 ]\n",
      " [0.44951892]\n",
      " [0.42246902]\n",
      " [0.43915144]\n",
      " [0.37827107]\n",
      " [0.39800993]\n",
      " [0.4998003 ]\n",
      " [0.36759886]\n",
      " [0.36415467]\n",
      " [0.48351866]\n",
      " [0.4677981 ]\n",
      " [0.4499998 ]\n",
      " [0.46734825]\n",
      " [0.54276806]\n",
      " [0.39351982]\n",
      " [0.43862113]\n",
      " [0.48631227]\n",
      " [0.46956307]\n",
      " [0.4642936 ]\n",
      " [0.39936185]\n",
      " [0.41573957]\n",
      " [0.4271585 ]\n",
      " [0.49629444]\n",
      " [0.52734673]\n",
      " [0.40711036]\n",
      " [0.45101467]\n",
      " [0.3299056 ]\n",
      " [0.41078377]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['score']=pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test=test.drop('features',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10941</td>\n",
       "      <td>[point, today, someone, says, something, remot...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.464979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10942</td>\n",
       "      <td>[game, day, minus, #relentless]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.386990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10943</td>\n",
       "      <td>[game, pissed, off, than, game, year, blood, b...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.518777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10944</td>\n",
       "      <td>[ive, found, candice, candace, she, pout, she,...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.397251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10945</td>\n",
       "      <td>[cant, come, muma, th, after, tweets, then, #s...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.462135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>11696</td>\n",
       "      <td>[what, supposed, animosity, bullshit, con, ira...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.527347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>11697</td>\n",
       "      <td>[byus, offense, score, vs, wvu]</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.407110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>11698</td>\n",
       "      <td>[id, love, gyimah, action, his, coach, holding...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.451015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>11699</td>\n",
       "      <td>[forgiving, means, operating, gods, spirit, am...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.329906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>11700</td>\n",
       "      <td>[ive, got, lot, tokens, saved, wanna, spam, ev...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.410784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  \\\n",
       "0    10941  [point, today, someone, says, something, remot...   anger   \n",
       "1    10942                    [game, day, minus, #relentless]   anger   \n",
       "2    10943  [game, pissed, off, than, game, year, blood, b...   anger   \n",
       "3    10944  [ive, found, candice, candace, she, pout, she,...   anger   \n",
       "4    10945  [cant, come, muma, th, after, tweets, then, #s...   anger   \n",
       "..     ...                                                ...     ...   \n",
       "755  11696  [what, supposed, animosity, bullshit, con, ira...   anger   \n",
       "756  11697                    [byus, offense, score, vs, wvu]   anger   \n",
       "757  11698  [id, love, gyimah, action, his, coach, holding...   anger   \n",
       "758  11699  [forgiving, means, operating, gods, spirit, am...   anger   \n",
       "759  11700  [ive, got, lot, tokens, saved, wanna, spam, ev...   anger   \n",
       "\n",
       "        score  \n",
       "0    0.464979  \n",
       "1    0.386990  \n",
       "2    0.518777  \n",
       "3    0.397251  \n",
       "4    0.462135  \n",
       "..        ...  \n",
       "755  0.527347  \n",
       "756  0.407110  \n",
       "757  0.451015  \n",
       "758  0.329906  \n",
       "759  0.410784  \n",
       "\n",
       "[760 rows x 4 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
