{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.read_csv(\"Desktop/emoint tweet/joy-ratings-0to1.train.txt\", delimiter='\\t', header=None)\n",
    "df1.columns = ['Id', 'tweet', 'emotion', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Id                                              tweet emotion  score\n",
      "0    30000  Just got back from seeing @GaryDelaney in Burs...     joy  0.980\n",
      "1    30001  Oh dear an evening of absolute hilarity I don'...     joy  0.958\n",
      "2    30002  Been waiting all week for this game ❤️❤️❤️ #ch...     joy  0.940\n",
      "3    30003  @gardiner_love : Thank you so much, Gloria! Yo...     joy  0.938\n",
      "4    30004  I feel so blessed to work with the family that...     joy  0.938\n",
      "..     ...                                                ...     ...    ...\n",
      "818  30818  It's just the lack of company and liveliness o...     joy  0.058\n",
      "819  30819             Quinn's short hair makes me sad. #glee     joy  0.040\n",
      "820  30820  hate overthinking e v e r y t h i n g like i j...     joy  0.040\n",
      "821  30821  People who cheer for sports teams completely o...     joy  0.020\n",
      "822  30822  @DamnPatriot You're a POS for rejoicing in som...     joy  0.019\n",
      "\n",
      "[823 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import emoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", tweet)\n",
    "    \n",
    "    return tweet\n",
    "df1['tweet'] = df1['tweet'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mentions(tweet):\n",
    "    return re.sub(r'@\\w+', '', tweet)\n",
    "\n",
    "df1['tweet'] = df1['tweet'].apply(remove_mentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s#@]', '', text)  # Remove all non-word characters except # and @ symbols\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df1['tweet'] = df1['tweet'].apply(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>just got back from seeing in burslem amazing f...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>oh dear an evening of absolute hilarity i dont...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>been waiting all week for this game #cheer #fr...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>thank you so much gloria youre so sweet and th...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>i feel so blessed to work with the family that...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>30818</td>\n",
       "      <td>its just the lack of company and liveliness ou...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>30819</td>\n",
       "      <td>quinns short hair makes me sad #glee</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>30820</td>\n",
       "      <td>hate overthinking e v e r y t h i n g like i j...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>30821</td>\n",
       "      <td>people who cheer for sports teams completely o...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>30822</td>\n",
       "      <td>youre a pos for rejoicing in someones death</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>823 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score\n",
       "0    30000  just got back from seeing in burslem amazing f...     joy  0.980\n",
       "1    30001  oh dear an evening of absolute hilarity i dont...     joy  0.958\n",
       "2    30002  been waiting all week for this game #cheer #fr...     joy  0.940\n",
       "3    30003  thank you so much gloria youre so sweet and th...     joy  0.938\n",
       "4    30004  i feel so blessed to work with the family that...     joy  0.938\n",
       "..     ...                                                ...     ...    ...\n",
       "818  30818  its just the lack of company and liveliness ou...     joy  0.058\n",
       "819  30819               quinns short hair makes me sad #glee     joy  0.040\n",
       "820  30820  hate overthinking e v e r y t h i n g like i j...     joy  0.040\n",
       "821  30821  people who cheer for sports teams completely o...     joy  0.020\n",
       "822  30822        youre a pos for rejoicing in someones death     joy  0.019\n",
       "\n",
       "[823 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emoji(tweet):\n",
    "    text = emoji.demojize(tweet)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['tweet'] = df1['tweet'].apply(convert_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweets(tweet):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    return tokenizer.tokenize(tweet)\n",
    "\n",
    "df1['tweet'] = df1['tweet'].apply(tokenize_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>[just, got, back, from, seeing, in, burslem, a...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>[oh, dear, an, evening, of, absolute, hilarity...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>[been, waiting, all, week, for, this, game, #c...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>[thank, you, so, much, gloria, youre, so, swee...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>[i, feel, so, blessed, to, work, with, the, fa...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>30818</td>\n",
       "      <td>[its, just, the, lack, of, company, and, livel...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>30819</td>\n",
       "      <td>[quinns, short, hair, makes, me, sad, #glee]</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>30820</td>\n",
       "      <td>[hate, overthinking, e, v, e, r, y, t, h, i, n...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>30821</td>\n",
       "      <td>[people, who, cheer, for, sports, teams, compl...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>30822</td>\n",
       "      <td>[youre, a, pos, for, rejoicing, in, someones, ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>823 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score\n",
       "0    30000  [just, got, back, from, seeing, in, burslem, a...     joy  0.980\n",
       "1    30001  [oh, dear, an, evening, of, absolute, hilarity...     joy  0.958\n",
       "2    30002  [been, waiting, all, week, for, this, game, #c...     joy  0.940\n",
       "3    30003  [thank, you, so, much, gloria, youre, so, swee...     joy  0.938\n",
       "4    30004  [i, feel, so, blessed, to, work, with, the, fa...     joy  0.938\n",
       "..     ...                                                ...     ...    ...\n",
       "818  30818  [its, just, the, lack, of, company, and, livel...     joy  0.058\n",
       "819  30819       [quinns, short, hair, makes, me, sad, #glee]     joy  0.040\n",
       "820  30820  [hate, overthinking, e, v, e, r, y, t, h, i, n...     joy  0.040\n",
       "821  30821  [people, who, cheer, for, sports, teams, compl...     joy  0.020\n",
       "822  30822  [youre, a, pos, for, rejoicing, in, someones, ...     joy  0.019\n",
       "\n",
       "[823 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a list of stopwords\n",
    "stop_words = [\n",
    "    'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'he', 'in', 'is','this','all'\n",
    "    'it', 'its', 'of', 'on', 'that', 'the', 'to', 'was', 'were', 'will', 'with', 'i', 'you', 'your','so'\n",
    "]\n",
    "\n",
    "# Function to remove stopwords and single-letter words from a list of tokens\n",
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [token for token in tokens if len(token) > 1 and token.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "# Apply the remove_stopwords function to the 'tweet' column\n",
    "df1['tweet'] = df1['tweet'].apply(remove_stopwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>[just, got, back, seeing, burslem, amazing, fa...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>[oh, dear, evening, absolute, hilarity, dont, ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>[been, waiting, all, week, game, #cheer, #friday]</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>[thank, much, gloria, youre, sweet, thoughtful...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>[feel, blessed, work, family, nanny, nothing, ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>30818</td>\n",
       "      <td>[just, lack, company, liveliness, out, here, m...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>30819</td>\n",
       "      <td>[quinns, short, hair, makes, me, sad, #glee]</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>30820</td>\n",
       "      <td>[hate, overthinking, like, jus, wanna, happy, ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>30821</td>\n",
       "      <td>[people, who, cheer, sports, teams, completely...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>30822</td>\n",
       "      <td>[youre, pos, rejoicing, someones, death]</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>823 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score\n",
       "0    30000  [just, got, back, seeing, burslem, amazing, fa...     joy  0.980\n",
       "1    30001  [oh, dear, evening, absolute, hilarity, dont, ...     joy  0.958\n",
       "2    30002  [been, waiting, all, week, game, #cheer, #friday]     joy  0.940\n",
       "3    30003  [thank, much, gloria, youre, sweet, thoughtful...     joy  0.938\n",
       "4    30004  [feel, blessed, work, family, nanny, nothing, ...     joy  0.938\n",
       "..     ...                                                ...     ...    ...\n",
       "818  30818  [just, lack, company, liveliness, out, here, m...     joy  0.058\n",
       "819  30819       [quinns, short, hair, makes, me, sad, #glee]     joy  0.040\n",
       "820  30820  [hate, overthinking, like, jus, wanna, happy, ...     joy  0.040\n",
       "821  30821  [people, who, cheer, sports, teams, completely...     joy  0.020\n",
       "822  30822           [youre, pos, rejoicing, someones, death]     joy  0.019\n",
       "\n",
       "[823 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to extract features from a tokenized tweet\n",
    "def extract_features(tweet):\n",
    "    # Convert the list of tokens to a string\n",
    "    tokenized_text = ' '.join(tweet)\n",
    "    \n",
    "    # Tokenize the text using BERT tokenizer\n",
    "    input_ids = torch.tensor(tokenizer.encode(tokenized_text, add_special_tokens=True)).unsqueeze(0)\n",
    "    \n",
    "    # Pass the input tensor through the BERT model to extract features\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    \n",
    "    # Get the last layer hidden states\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    \n",
    "    # Extract the features from the last hidden states\n",
    "    features = last_hidden_states.squeeze(0).numpy()\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Apply feature extraction to the 'tweet' column of the DataFrame\n",
    "df1['features'] = df1['tweet'].apply(extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>[just, got, back, seeing, burslem, amazing, fa...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.980</td>\n",
       "      <td>[[-0.25902194, 0.021936538, 0.5708762, -0.6156...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>[oh, dear, evening, absolute, hilarity, dont, ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.958</td>\n",
       "      <td>[[0.11824173, 0.13200244, 0.048643403, -0.2167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>[been, waiting, all, week, game, #cheer, #friday]</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.940</td>\n",
       "      <td>[[-0.10390823, 0.012376993, -0.11558945, 0.009...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>[thank, much, gloria, youre, sweet, thoughtful...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "      <td>[[0.011071219, -0.05531338, 0.16319497, -0.004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>[feel, blessed, work, family, nanny, nothing, ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "      <td>[[-0.08090295, 0.37672976, 0.34673566, -0.3677...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>30818</td>\n",
       "      <td>[just, lack, company, liveliness, out, here, m...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.058</td>\n",
       "      <td>[[0.2985258, 0.44204718, 0.40646386, -0.412263...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>30819</td>\n",
       "      <td>[quinns, short, hair, makes, me, sad, #glee]</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.040</td>\n",
       "      <td>[[-0.06435747, -0.11854539, 0.3118093, -0.0855...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>30820</td>\n",
       "      <td>[hate, overthinking, like, jus, wanna, happy, ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.040</td>\n",
       "      <td>[[-0.2011238, 0.43611714, -0.2035487, 0.024425...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>30821</td>\n",
       "      <td>[people, who, cheer, sports, teams, completely...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.020</td>\n",
       "      <td>[[0.09072961, 0.124670625, -0.05488845, -0.106...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>30822</td>\n",
       "      <td>[youre, pos, rejoicing, someones, death]</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.019</td>\n",
       "      <td>[[-0.14432703, 0.5028677, -0.2449497, 0.108671...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>823 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                              tweet emotion  score  \\\n",
       "0    30000  [just, got, back, seeing, burslem, amazing, fa...     joy  0.980   \n",
       "1    30001  [oh, dear, evening, absolute, hilarity, dont, ...     joy  0.958   \n",
       "2    30002  [been, waiting, all, week, game, #cheer, #friday]     joy  0.940   \n",
       "3    30003  [thank, much, gloria, youre, sweet, thoughtful...     joy  0.938   \n",
       "4    30004  [feel, blessed, work, family, nanny, nothing, ...     joy  0.938   \n",
       "..     ...                                                ...     ...    ...   \n",
       "818  30818  [just, lack, company, liveliness, out, here, m...     joy  0.058   \n",
       "819  30819       [quinns, short, hair, makes, me, sad, #glee]     joy  0.040   \n",
       "820  30820  [hate, overthinking, like, jus, wanna, happy, ...     joy  0.040   \n",
       "821  30821  [people, who, cheer, sports, teams, completely...     joy  0.020   \n",
       "822  30822           [youre, pos, rejoicing, someones, death]     joy  0.019   \n",
       "\n",
       "                                              features  \n",
       "0    [[-0.25902194, 0.021936538, 0.5708762, -0.6156...  \n",
       "1    [[0.11824173, 0.13200244, 0.048643403, -0.2167...  \n",
       "2    [[-0.10390823, 0.012376993, -0.11558945, 0.009...  \n",
       "3    [[0.011071219, -0.05531338, 0.16319497, -0.004...  \n",
       "4    [[-0.08090295, 0.37672976, 0.34673566, -0.3677...  \n",
       "..                                                 ...  \n",
       "818  [[0.2985258, 0.44204718, 0.40646386, -0.412263...  \n",
       "819  [[-0.06435747, -0.11854539, 0.3118093, -0.0855...  \n",
       "820  [[-0.2011238, 0.43611714, -0.2035487, 0.024425...  \n",
       "821  [[0.09072961, 0.124670625, -0.05488845, -0.106...  \n",
       "822  [[-0.14432703, 0.5028677, -0.2449497, 0.108671...  \n",
       "\n",
       "[823 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 768)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>[just, got, back, seeing, burslem, amazing, fa...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.980</td>\n",
       "      <td>[[-0.25902194, 0.021936538, 0.5708762, -0.6156...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>[oh, dear, evening, absolute, hilarity, dont, ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.958</td>\n",
       "      <td>[[0.11824173, 0.13200244, 0.048643403, -0.2167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>[been, waiting, all, week, game, #cheer, #friday]</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.940</td>\n",
       "      <td>[[-0.10390823, 0.012376993, -0.11558945, 0.009...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>[thank, much, gloria, youre, sweet, thoughtful...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "      <td>[[0.011071219, -0.05531338, 0.16319497, -0.004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>[feel, blessed, work, family, nanny, nothing, ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.938</td>\n",
       "      <td>[[-0.08090295, 0.37672976, 0.34673566, -0.3677...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30005</td>\n",
       "      <td>[today, reached, subscribers, yt, #goodday, #t...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.926</td>\n",
       "      <td>[[-0.05542418, -0.051494613, 0.16199583, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30006</td>\n",
       "      <td>[good, morning, love, happy, first, day, fall,...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.924</td>\n",
       "      <td>[[-0.112404265, -0.09642104, 0.22093175, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30007</td>\n",
       "      <td>[#bridgetjonesbaby, best, thing, ive, seen, ag...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.922</td>\n",
       "      <td>[[-0.34465936, 0.017047953, -0.1802155, -0.035...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30008</td>\n",
       "      <td>[just, got, back, seeing, burslem, amazing, fa...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.920</td>\n",
       "      <td>[[0.10194833, 0.3232219, 0.32963663, -0.629902...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30009</td>\n",
       "      <td>[thought, holidays, could, not, get, any, more...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.917</td>\n",
       "      <td>[[-0.08916461, 0.0760634, 0.11607354, -0.01644...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id                                              tweet emotion  score  \\\n",
       "0  30000  [just, got, back, seeing, burslem, amazing, fa...     joy  0.980   \n",
       "1  30001  [oh, dear, evening, absolute, hilarity, dont, ...     joy  0.958   \n",
       "2  30002  [been, waiting, all, week, game, #cheer, #friday]     joy  0.940   \n",
       "3  30003  [thank, much, gloria, youre, sweet, thoughtful...     joy  0.938   \n",
       "4  30004  [feel, blessed, work, family, nanny, nothing, ...     joy  0.938   \n",
       "5  30005  [today, reached, subscribers, yt, #goodday, #t...     joy  0.926   \n",
       "6  30006  [good, morning, love, happy, first, day, fall,...     joy  0.924   \n",
       "7  30007  [#bridgetjonesbaby, best, thing, ive, seen, ag...     joy  0.922   \n",
       "8  30008  [just, got, back, seeing, burslem, amazing, fa...     joy  0.920   \n",
       "9  30009  [thought, holidays, could, not, get, any, more...     joy  0.917   \n",
       "\n",
       "                                            features  \n",
       "0  [[-0.25902194, 0.021936538, 0.5708762, -0.6156...  \n",
       "1  [[0.11824173, 0.13200244, 0.048643403, -0.2167...  \n",
       "2  [[-0.10390823, 0.012376993, -0.11558945, 0.009...  \n",
       "3  [[0.011071219, -0.05531338, 0.16319497, -0.004...  \n",
       "4  [[-0.08090295, 0.37672976, 0.34673566, -0.3677...  \n",
       "5  [[-0.05542418, -0.051494613, 0.16199583, -0.01...  \n",
       "6  [[-0.112404265, -0.09642104, 0.22093175, -0.08...  \n",
       "7  [[-0.34465936, 0.017047953, -0.1802155, -0.035...  \n",
       "8  [[0.10194833, 0.3232219, 0.32963663, -0.629902...  \n",
       "9  [[-0.08916461, 0.0760634, 0.11607354, -0.01644...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Assuming df1 is your DataFrame\n",
    "features = df1['features'].tolist()\n",
    "\n",
    "# Pad the nested arrays\n",
    "padded_features = pad_sequences(features, padding='post')\n",
    "\n",
    "# Convert the padded features back to a DataFrame\n",
    "padded_df = df1.copy()\n",
    "padded_df['features'] = padded_features.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input feature shape: (823, 42, 768)\n"
     ]
    }
   ],
   "source": [
    "X = np.stack(padded_df['features'])\n",
    "\n",
    "# Print the shape of the input feature array\n",
    "print('Input feature shape:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (823, 42, 768)\n",
      "Output shape: (823,)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(padded_df['score'])     # Output variable\n",
    "\n",
    "# Print the shape of the input and output sets\n",
    "print(\"Input shape:\", X.shape)\n",
    "print(\"Output shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(X, (823, 42 * 768))  # Reshape input to 2D\n",
    "y = np.reshape(y, (823,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# print(type(df1['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TypeError                                 Traceback (most recent call last)\n",
    "# <ipython-input-31-c5644810a03e> in <module>\n",
    "#       1 tweets = df1['tweet'].tolist()\n",
    "# ----> 2 joined_tweets = ' '.join(tweets)\n",
    "#       3 \n",
    "#       4 vectorizer_tfidf = TfidfVectorizer()\n",
    "#       5 X_tfidf = vectorizer_tfidf.fit_transform([joined_tweets])\n",
    "\n",
    "# TypeError: sequence item 0: expected str instance, list found\n",
    "# import numpy as np\n",
    "\n",
    "# input_data = df1.features  # Replace with your input data\n",
    "# train_X = np.array(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check dimensions of X_tfidf and emotions\n",
    "# print(\"X_tfidf shape:\", X_tfidf.shape)\n",
    "# print(\"emotions shape:\", emotions.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# train_X = X_tfidf.copy()\n",
    "     \n",
    "\n",
    "# train_X.to_numpy()\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(823, 32256)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df1['score'].copy()\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols = ['id', 'tweet', 'emotion', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.read_csv(\"Desktop/emoint tweet/joy-ratings-0to1.dev.gold.txt\", header=None, sep='\\t', names=cols, index_col=0)\n",
    "\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_tweet(tweet):\n",
    "#     tweet = tweet.lower()\n",
    "#     tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", tweet)\n",
    "    \n",
    "#     return tweet\n",
    "# df2['tweet'] = df2['tweet'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_mentions(tweet):\n",
    "#     return re.sub(r'@\\w+', '', tweet)\n",
    "\n",
    "# df2['tweet'] = df2['tweet'].apply(remove_mentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(text):\n",
    "#     text = re.sub(r'[^\\w\\s#@]', '', text)  # Remove all non-word characters except # and @ symbols\n",
    "#     text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "#     text = re.sub(r'\\s+', ' ', text).strip()\n",
    "#     return text\n",
    "\n",
    "# df2['tweet'] = df2['tweet'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_emoji(tweet):\n",
    "#     text = emoji.demojize(tweet)\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2['tweet'] = df2['tweet'].apply(convert_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_tweets(tweet):\n",
    "#     tokenizer = TweetTokenizer()\n",
    "#     return tokenizer.tokenize(tweet)\n",
    "# df2['tweet'] = df2['tweet'].astype(str)\n",
    "# df2['tweet'] = df2['tweet'].apply(tokenize_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define a list of stopwords\n",
    "# stop_words = [\n",
    "#     'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'he', 'in', 'is','this','all'\n",
    "#     'it', 'its', 'of', 'on', 'that', 'the', 'to', 'was', 'were', 'will', 'with', 'i', 'you', 'your','so'\n",
    "# ]\n",
    "\n",
    "# # Function to remove stopwords and single-letter words from a list of tokens\n",
    "# def remove_stopwords(tokens):\n",
    "#     filtered_tokens = [token for token in tokens if len(token) > 1 and token.lower() not in stop_words]\n",
    "#     return filtered_tokens\n",
    "\n",
    "# # Apply the remove_stopwords function to the 'tweet' column\n",
    "# df2['tweet'] = df2['tweet'].apply(remove_stopwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer_tfidf = TfidfVectorizer()\n",
    "\n",
    "# vectorizer_tfidf.fit(df1)\n",
    "# X_tfidf = vectorizer_tfidf.fit_transform(df2)\n",
    "# X_tfidf = pd.DataFrame.sparse.from_spmatrix(X_tfidf)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_X = X_Dev_tfidf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_Dev_tfidf = vectorizer_tfidf.transform(df2)\n",
    "# #X_Dev_tfidf = pd.DataFrame.sparse.from_spmatrix(X_Dev_tfidf)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_X = X_Dev_tfidf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_X.to_numpy()\n",
    "#      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# val_Y=df1['score'].copy()\n",
    "# val_Y.to_numpy()\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_Y.to_numpy()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import BertModel, BertTokenizer\n",
    "\n",
    "\n",
    "# # Load the pre-trained BERT model and tokenizer\n",
    "# model_name = 'bert-base-uncased'\n",
    "# tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "# model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# # Function to extract features from a tokenized tweet\n",
    "# def extract_features(tweet):\n",
    "#     # Convert the list of tokens to a string\n",
    "#     tokenized_text = ' '.join(tweet)\n",
    "    \n",
    "#     # Tokenize the text using BERT tokenizer\n",
    "#     input_ids = torch.tensor(tokenizer.encode(tokenized_text, add_special_tokens=True)).unsqueeze(0)\n",
    "    \n",
    "#     # Pass the input tensor through the BERT model to extract features\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(input_ids)\n",
    "    \n",
    "#     # Get the last layer hidden states\n",
    "#     last_hidden_states = outputs.last_hidden_state\n",
    "    \n",
    "#     # Extract the features from the last hidden states\n",
    "#     features = last_hidden_states.squeeze(0).numpy()\n",
    "    \n",
    "#     return features\n",
    "\n",
    "# # Apply feature extraction to the 'tweet' column of the DataFrame\n",
    "# df2['features'] = df2['tweet'].apply(extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32256)             1040481792\n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32256)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               16515584  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,057,030,273\n",
      "Trainable params: 1,057,030,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "model = Sequential()\n",
    "model.add(Dense(32256, input_shape=(32256,), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='mae', optimizer=optimiser ,metrics=[\"mae\"])\n",
    "model.summary()\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to strings\n",
    "df1['tweet'] = df1['tweet'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "# Convert DataFrame to NumPy array\n",
    "#Convert DataFrame column to NumPy array\n",
    "array = df1['tweet'].values\n",
    "\n",
    "# Convert NumPy array to TensorFlow tensor\n",
    "tensor = tf.convert_to_tensor(array)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X,Y,batch_size=32,epochs=10,shuffle=True,verbose=1)#callbacks=stopping_criterions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
